Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.
======================================================================
PHASE 2: ADVANCED TICKET CLUSTERING
Sentence Transformers + HDBSCAN + BERTopic + UMAP
======================================================================
[OK] Loaded 100 tickets with 3 columns
[INFO] Columns: ticket_id, created_at, conversation

[EMBED] Generating embeddings with all-MiniLM-L6-v2...
[INFO] Model will download on first run (~90MB)

Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]
Loading weights:   1%|          | 1/103 [00:00<?, ?it/s, Materializing param=embeddings.LayerNorm.bias]
Loading weights:   1%|          | 1/103 [00:00<?, ?it/s, Materializing param=embeddings.LayerNorm.bias]
Loading weights:   2%|1         | 2/103 [00:00<00:00, 2005.88it/s, Materializing param=embeddings.LayerNorm.weight]
Loading weights:   2%|1         | 2/103 [00:00<00:00, 2005.88it/s, Materializing param=embeddings.LayerNorm.weight]
Loading weights:   3%|2         | 3/103 [00:00<00:00, 1279.66it/s, Materializing param=embeddings.position_embeddings.weight]
Loading weights:   3%|2         | 3/103 [00:00<00:00, 1279.66it/s, Materializing param=embeddings.position_embeddings.weight]
Loading weights:   4%|3         | 4/103 [00:00<00:00, 1198.03it/s, Materializing param=embeddings.token_type_embeddings.weight]
Loading weights:   4%|3         | 4/103 [00:00<00:00, 626.88it/s, Materializing param=embeddings.token_type_embeddings.weight] 
Loading weights:   5%|4         | 5/103 [00:00<00:00, 783.60it/s, Materializing param=embeddings.word_embeddings.weight]      
Loading weights:   5%|4         | 5/103 [00:00<00:00, 783.60it/s, Materializing param=embeddings.word_embeddings.weight]
Loading weights:   6%|5         | 6/103 [00:00<00:00, 782.01it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.bias]
Loading weights:   6%|5         | 6/103 [00:00<00:00, 782.01it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.bias]
Loading weights:   7%|6         | 7/103 [00:00<00:00, 762.54it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.weight]
Loading weights:   7%|6         | 7/103 [00:00<00:00, 762.54it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.weight]
Loading weights:   8%|7         | 8/103 [00:00<00:00, 784.81it/s, Materializing param=encoder.layer.0.attention.output.dense.bias]      
Loading weights:   8%|7         | 8/103 [00:00<00:00, 784.81it/s, Materializing param=encoder.layer.0.attention.output.dense.bias]
Loading weights:   9%|8         | 9/103 [00:00<00:00, 804.00it/s, Materializing param=encoder.layer.0.attention.output.dense.weight]
Loading weights:   9%|8         | 9/103 [00:00<00:00, 804.00it/s, Materializing param=encoder.layer.0.attention.output.dense.weight]
Loading weights:  10%|9         | 10/103 [00:00<00:00, 820.24it/s, Materializing param=encoder.layer.0.attention.self.key.bias]     
Loading weights:  10%|9         | 10/103 [00:00<00:00, 820.24it/s, Materializing param=encoder.layer.0.attention.self.key.bias]
Loading weights:  11%|#         | 11/103 [00:00<00:00, 802.86it/s, Materializing param=encoder.layer.0.attention.self.key.weight]
Loading weights:  11%|#         | 11/103 [00:00<00:00, 747.74it/s, Materializing param=encoder.layer.0.attention.self.key.weight]
Loading weights:  12%|#1        | 12/103 [00:00<00:00, 788.49it/s, Materializing param=encoder.layer.0.attention.self.query.bias]
Loading weights:  12%|#1        | 12/103 [00:00<00:00, 739.24it/s, Materializing param=encoder.layer.0.attention.self.query.bias]
Loading weights:  13%|#2        | 13/103 [00:00<00:00, 712.85it/s, Materializing param=encoder.layer.0.attention.self.query.weight]
Loading weights:  13%|#2        | 13/103 [00:00<00:00, 675.83it/s, Materializing param=encoder.layer.0.attention.self.query.weight]
Loading weights:  14%|#3        | 14/103 [00:00<00:00, 692.06it/s, Materializing param=encoder.layer.0.attention.self.value.bias]  
Loading weights:  14%|#3        | 14/103 [00:00<00:00, 692.06it/s, Materializing param=encoder.layer.0.attention.self.value.bias]
Loading weights:  15%|#4        | 15/103 [00:00<00:00, 689.83it/s, Materializing param=encoder.layer.0.attention.self.value.weight]
Loading weights:  15%|#4        | 15/103 [00:00<00:00, 659.23it/s, Materializing param=encoder.layer.0.attention.self.value.weight]
Loading weights:  16%|#5        | 16/103 [00:00<00:00, 673.47it/s, Materializing param=encoder.layer.0.intermediate.dense.bias]    
Loading weights:  16%|#5        | 16/103 [00:00<00:00, 646.32it/s, Materializing param=encoder.layer.0.intermediate.dense.bias]
Loading weights:  17%|#6        | 17/103 [00:00<00:00, 660.07it/s, Materializing param=encoder.layer.0.intermediate.dense.weight]
Loading weights:  17%|#6        | 17/103 [00:00<00:00, 660.07it/s, Materializing param=encoder.layer.0.intermediate.dense.weight]
Loading weights:  17%|#7        | 18/103 [00:00<00:00, 659.95it/s, Materializing param=encoder.layer.0.output.LayerNorm.bias]    
Loading weights:  17%|#7        | 18/103 [00:00<00:00, 636.59it/s, Materializing param=encoder.layer.0.output.LayerNorm.bias]
Loading weights:  18%|#8        | 19/103 [00:00<00:00, 627.60it/s, Materializing param=encoder.layer.0.output.LayerNorm.weight]
Loading weights:  18%|#8        | 19/103 [00:00<00:00, 579.37it/s, Materializing param=encoder.layer.0.output.LayerNorm.weight]
Loading weights:  19%|#9        | 20/103 [00:00<00:00, 591.82it/s, Materializing param=encoder.layer.0.output.dense.bias]      
Loading weights:  19%|#9        | 20/103 [00:00<00:00, 591.82it/s, Materializing param=encoder.layer.0.output.dense.bias]
Loading weights:  20%|##        | 21/103 [00:00<00:00, 603.53it/s, Materializing param=encoder.layer.0.output.dense.weight]
Loading weights:  20%|##        | 21/103 [00:00<00:00, 603.53it/s, Materializing param=encoder.layer.0.output.dense.weight]
Loading weights:  21%|##1       | 22/103 [00:00<00:00, 632.27it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.bias]
Loading weights:  21%|##1       | 22/103 [00:00<00:00, 632.27it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.bias]
Loading weights:  22%|##2       | 23/103 [00:00<00:00, 642.49it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.weight]
Loading weights:  22%|##2       | 23/103 [00:00<00:00, 642.49it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.weight]
Loading weights:  23%|##3       | 24/103 [00:00<00:00, 670.43it/s, Materializing param=encoder.layer.1.attention.output.dense.bias]      
Loading weights:  23%|##3       | 24/103 [00:00<00:00, 670.43it/s, Materializing param=encoder.layer.1.attention.output.dense.bias]
Loading weights:  24%|##4       | 25/103 [00:00<00:00, 679.45it/s, Materializing param=encoder.layer.1.attention.output.dense.weight]
Loading weights:  24%|##4       | 25/103 [00:00<00:00, 679.45it/s, Materializing param=encoder.layer.1.attention.output.dense.weight]
Loading weights:  25%|##5       | 26/103 [00:00<00:00, 706.62it/s, Materializing param=encoder.layer.1.attention.self.key.bias]      
Loading weights:  25%|##5       | 26/103 [00:00<00:00, 706.62it/s, Materializing param=encoder.layer.1.attention.self.key.bias]
Loading weights:  26%|##6       | 27/103 [00:00<00:00, 714.38it/s, Materializing param=encoder.layer.1.attention.self.key.weight]
Loading weights:  26%|##6       | 27/103 [00:00<00:00, 714.38it/s, Materializing param=encoder.layer.1.attention.self.key.weight]
Loading weights:  27%|##7       | 28/103 [00:00<00:00, 740.84it/s, Materializing param=encoder.layer.1.attention.self.query.bias]
Loading weights:  27%|##7       | 28/103 [00:00<00:00, 740.84it/s, Materializing param=encoder.layer.1.attention.self.query.bias]
Loading weights:  28%|##8       | 29/103 [00:00<00:00, 747.52it/s, Materializing param=encoder.layer.1.attention.self.query.weight]
Loading weights:  28%|##8       | 29/103 [00:00<00:00, 747.52it/s, Materializing param=encoder.layer.1.attention.self.query.weight]
Loading weights:  29%|##9       | 30/103 [00:00<00:00, 763.15it/s, Materializing param=encoder.layer.1.attention.self.value.bias]  
Loading weights:  29%|##9       | 30/103 [00:00<00:00, 763.15it/s, Materializing param=encoder.layer.1.attention.self.value.bias]
Loading weights:  30%|###       | 31/103 [00:00<00:00, 788.58it/s, Materializing param=encoder.layer.1.attention.self.value.weight]
Loading weights:  30%|###       | 31/103 [00:00<00:00, 788.58it/s, Materializing param=encoder.layer.1.attention.self.value.weight]
Loading weights:  31%|###1      | 32/103 [00:00<00:00, 793.53it/s, Materializing param=encoder.layer.1.intermediate.dense.bias]    
Loading weights:  31%|###1      | 32/103 [00:00<00:00, 793.53it/s, Materializing param=encoder.layer.1.intermediate.dense.bias]
Loading weights:  32%|###2      | 33/103 [00:00<00:00, 818.32it/s, Materializing param=encoder.layer.1.intermediate.dense.weight]
Loading weights:  32%|###2      | 33/103 [00:00<00:00, 818.32it/s, Materializing param=encoder.layer.1.intermediate.dense.weight]
Loading weights:  33%|###3      | 34/103 [00:00<00:00, 822.65it/s, Materializing param=encoder.layer.1.output.LayerNorm.bias]    
Loading weights:  33%|###3      | 34/103 [00:00<00:00, 822.65it/s, Materializing param=encoder.layer.1.output.LayerNorm.bias]
Loading weights:  34%|###3      | 35/103 [00:00<00:00, 846.85it/s, Materializing param=encoder.layer.1.output.LayerNorm.weight]
Loading weights:  34%|###3      | 35/103 [00:00<00:00, 846.85it/s, Materializing param=encoder.layer.1.output.LayerNorm.weight]
Loading weights:  35%|###4      | 36/103 [00:00<00:00, 850.37it/s, Materializing param=encoder.layer.1.output.dense.bias]      
Loading weights:  35%|###4      | 36/103 [00:00<00:00, 850.37it/s, Materializing param=encoder.layer.1.output.dense.bias]
Loading weights:  36%|###5      | 37/103 [00:00<00:00, 873.99it/s, Materializing param=encoder.layer.1.output.dense.weight]
Loading weights:  36%|###5      | 37/103 [00:00<00:00, 873.99it/s, Materializing param=encoder.layer.1.output.dense.weight]
Loading weights:  37%|###6      | 38/103 [00:00<00:00, 876.93it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.bias]
Loading weights:  37%|###6      | 38/103 [00:00<00:00, 876.93it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.bias]
Loading weights:  38%|###7      | 39/103 [00:00<00:00, 847.65it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.weight]
Loading weights:  38%|###7      | 39/103 [00:00<00:00, 829.41it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.weight]
Loading weights:  39%|###8      | 40/103 [00:00<00:00, 850.67it/s, Materializing param=encoder.layer.2.attention.output.dense.bias]      
Loading weights:  39%|###8      | 40/103 [00:00<00:00, 850.67it/s, Materializing param=encoder.layer.2.attention.output.dense.bias]
Loading weights:  40%|###9      | 41/103 [00:00<00:00, 853.76it/s, Materializing param=encoder.layer.2.attention.output.dense.weight]
Loading weights:  40%|###9      | 41/103 [00:00<00:00, 853.76it/s, Materializing param=encoder.layer.2.attention.output.dense.weight]
Loading weights:  41%|####      | 42/103 [00:00<00:00, 874.58it/s, Materializing param=encoder.layer.2.attention.self.key.bias]      
Loading weights:  41%|####      | 42/103 [00:00<00:00, 874.58it/s, Materializing param=encoder.layer.2.attention.self.key.bias]
Loading weights:  42%|####1     | 43/103 [00:00<00:00, 877.13it/s, Materializing param=encoder.layer.2.attention.self.key.weight]
Loading weights:  42%|####1     | 43/103 [00:00<00:00, 877.13it/s, Materializing param=encoder.layer.2.attention.self.key.weight]
Loading weights:  43%|####2     | 44/103 [00:00<00:00, 897.53it/s, Materializing param=encoder.layer.2.attention.self.query.bias]
Loading weights:  43%|####2     | 44/103 [00:00<00:00, 897.53it/s, Materializing param=encoder.layer.2.attention.self.query.bias]
Loading weights:  44%|####3     | 45/103 [00:00<00:00, 899.60it/s, Materializing param=encoder.layer.2.attention.self.query.weight]
Loading weights:  44%|####3     | 45/103 [00:00<00:00, 899.60it/s, Materializing param=encoder.layer.2.attention.self.query.weight]
Loading weights:  45%|####4     | 46/103 [00:00<00:00, 901.58it/s, Materializing param=encoder.layer.2.attention.self.value.bias]  
Loading weights:  45%|####4     | 46/103 [00:00<00:00, 901.58it/s, Materializing param=encoder.layer.2.attention.self.value.bias]
Loading weights:  46%|####5     | 47/103 [00:00<00:00, 921.17it/s, Materializing param=encoder.layer.2.attention.self.value.weight]
Loading weights:  46%|####5     | 47/103 [00:00<00:00, 921.17it/s, Materializing param=encoder.layer.2.attention.self.value.weight]
Loading weights:  47%|####6     | 48/103 [00:00<00:00, 922.70it/s, Materializing param=encoder.layer.2.intermediate.dense.bias]    
Loading weights:  47%|####6     | 48/103 [00:00<00:00, 922.70it/s, Materializing param=encoder.layer.2.intermediate.dense.bias]
Loading weights:  48%|####7     | 49/103 [00:00<00:00, 941.92it/s, Materializing param=encoder.layer.2.intermediate.dense.weight]
Loading weights:  48%|####7     | 49/103 [00:00<00:00, 941.92it/s, Materializing param=encoder.layer.2.intermediate.dense.weight]
Loading weights:  49%|####8     | 50/103 [00:00<00:00, 943.01it/s, Materializing param=encoder.layer.2.output.LayerNorm.bias]    
Loading weights:  49%|####8     | 50/103 [00:00<00:00, 943.01it/s, Materializing param=encoder.layer.2.output.LayerNorm.bias]
Loading weights:  50%|####9     | 51/103 [00:00<00:00, 961.87it/s, Materializing param=encoder.layer.2.output.LayerNorm.weight]
Loading weights:  50%|####9     | 51/103 [00:00<00:00, 961.87it/s, Materializing param=encoder.layer.2.output.LayerNorm.weight]
Loading weights:  50%|#####     | 52/103 [00:00<00:00, 962.58it/s, Materializing param=encoder.layer.2.output.dense.bias]      
Loading weights:  50%|#####     | 52/103 [00:00<00:00, 962.58it/s, Materializing param=encoder.layer.2.output.dense.bias]
Loading weights:  51%|#####1    | 53/103 [00:00<00:00, 981.09it/s, Materializing param=encoder.layer.2.output.dense.weight]
Loading weights:  51%|#####1    | 53/103 [00:00<00:00, 981.09it/s, Materializing param=encoder.layer.2.output.dense.weight]
Loading weights:  52%|#####2    | 54/103 [00:00<00:00, 999.60it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.bias]
Loading weights:  52%|#####2    | 54/103 [00:00<00:00, 981.41it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.bias]
Loading weights:  53%|#####3    | 55/103 [00:00<00:00, 999.59it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.weight]
Loading weights:  53%|#####3    | 55/103 [00:00<00:00, 999.59it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.weight]
Loading weights:  54%|#####4    | 56/103 [00:00<00:00, 999.62it/s, Materializing param=encoder.layer.3.attention.output.dense.bias]      
Loading weights:  54%|#####4    | 56/103 [00:00<00:00, 999.62it/s, Materializing param=encoder.layer.3.attention.output.dense.bias]
Loading weights:  55%|#####5    | 57/103 [00:00<00:00, 1008.32it/s, Materializing param=encoder.layer.3.attention.output.dense.weight]
Loading weights:  55%|#####5    | 57/103 [00:00<00:00, 1008.32it/s, Materializing param=encoder.layer.3.attention.output.dense.weight]
Loading weights:  56%|#####6    | 58/103 [00:00<00:00, 1026.01it/s, Materializing param=encoder.layer.3.attention.self.key.bias]      
Loading weights:  56%|#####6    | 58/103 [00:00<00:00, 990.73it/s, Materializing param=encoder.layer.3.attention.self.key.bias] 
Loading weights:  57%|#####7    | 59/103 [00:00<00:00, 990.91it/s, Materializing param=encoder.layer.3.attention.self.key.weight]
Loading weights:  57%|#####7    | 59/103 [00:00<00:00, 990.91it/s, Materializing param=encoder.layer.3.attention.self.key.weight]
Loading weights:  58%|#####8    | 60/103 [00:00<00:00, 1007.71it/s, Materializing param=encoder.layer.3.attention.self.query.bias]
Loading weights:  58%|#####8    | 60/103 [00:00<00:00, 991.03it/s, Materializing param=encoder.layer.3.attention.self.query.bias] 
Loading weights:  59%|#####9    | 61/103 [00:00<00:00, 1007.55it/s, Materializing param=encoder.layer.3.attention.self.query.weight]
Loading weights:  59%|#####9    | 61/103 [00:00<00:00, 1007.55it/s, Materializing param=encoder.layer.3.attention.self.query.weight]
Loading weights:  60%|######    | 62/103 [00:00<00:00, 1007.38it/s, Materializing param=encoder.layer.3.attention.self.value.bias]  
Loading weights:  60%|######    | 62/103 [00:00<00:00, 1007.38it/s, Materializing param=encoder.layer.3.attention.self.value.bias]
Loading weights:  61%|######1   | 63/103 [00:00<00:00, 1023.63it/s, Materializing param=encoder.layer.3.attention.self.value.weight]
Loading weights:  61%|######1   | 63/103 [00:00<00:00, 1023.63it/s, Materializing param=encoder.layer.3.attention.self.value.weight]
Loading weights:  62%|######2   | 64/103 [00:00<00:00, 1023.25it/s, Materializing param=encoder.layer.3.intermediate.dense.bias]    
Loading weights:  62%|######2   | 64/103 [00:00<00:00, 1023.25it/s, Materializing param=encoder.layer.3.intermediate.dense.bias]
Loading weights:  63%|######3   | 65/103 [00:00<00:00, 1022.92it/s, Materializing param=encoder.layer.3.intermediate.dense.weight]
Loading weights:  63%|######3   | 65/103 [00:00<00:00, 1022.92it/s, Materializing param=encoder.layer.3.intermediate.dense.weight]
Loading weights:  64%|######4   | 66/103 [00:00<00:00, 1038.66it/s, Materializing param=encoder.layer.3.output.LayerNorm.bias]    
Loading weights:  64%|######4   | 66/103 [00:00<00:00, 1038.66it/s, Materializing param=encoder.layer.3.output.LayerNorm.bias]
Loading weights:  65%|######5   | 67/103 [00:00<00:00, 1038.01it/s, Materializing param=encoder.layer.3.output.LayerNorm.weight]
Loading weights:  65%|######5   | 67/103 [00:00<00:00, 1038.01it/s, Materializing param=encoder.layer.3.output.LayerNorm.weight]
Loading weights:  66%|######6   | 68/103 [00:00<00:00, 1053.50it/s, Materializing param=encoder.layer.3.output.dense.bias]      
Loading weights:  66%|######6   | 68/103 [00:00<00:00, 1037.47it/s, Materializing param=encoder.layer.3.output.dense.bias]
Loading weights:  67%|######6   | 69/103 [00:00<00:00, 1052.72it/s, Materializing param=encoder.layer.3.output.dense.weight]
Loading weights:  67%|######6   | 69/103 [00:00<00:00, 1052.72it/s, Materializing param=encoder.layer.3.output.dense.weight]
Loading weights:  68%|######7   | 70/103 [00:00<00:00, 1051.98it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.bias]
Loading weights:  68%|######7   | 70/103 [00:00<00:00, 1044.07it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.bias]
Loading weights:  69%|######8   | 71/103 [00:00<00:00, 1058.98it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.weight]
Loading weights:  69%|######8   | 71/103 [00:00<00:00, 1058.98it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.weight]
Loading weights:  70%|######9   | 72/103 [00:00<00:00, 1073.90it/s, Materializing param=encoder.layer.4.attention.output.dense.bias]      
Loading weights:  70%|######9   | 72/103 [00:00<00:00, 1057.95it/s, Materializing param=encoder.layer.4.attention.output.dense.bias]
Loading weights:  71%|#######   | 73/103 [00:00<00:00, 1072.64it/s, Materializing param=encoder.layer.4.attention.output.dense.weight]
Loading weights:  71%|#######   | 73/103 [00:00<00:00, 1072.64it/s, Materializing param=encoder.layer.4.attention.output.dense.weight]
Loading weights:  72%|#######1  | 74/103 [00:00<00:00, 1087.34it/s, Materializing param=encoder.layer.4.attention.self.key.bias]      
Loading weights:  72%|#######1  | 74/103 [00:00<00:00, 1087.34it/s, Materializing param=encoder.layer.4.attention.self.key.bias]
Loading weights:  73%|#######2  | 75/103 [00:00<00:00, 1086.09it/s, Materializing param=encoder.layer.4.attention.self.key.weight]
Loading weights:  73%|#######2  | 75/103 [00:00<00:00, 1086.09it/s, Materializing param=encoder.layer.4.attention.self.key.weight]
Loading weights:  74%|#######3  | 76/103 [00:00<00:00, 1100.57it/s, Materializing param=encoder.layer.4.attention.self.query.bias]
Loading weights:  74%|#######3  | 76/103 [00:00<00:00, 1100.57it/s, Materializing param=encoder.layer.4.attention.self.query.bias]
Loading weights:  75%|#######4  | 77/103 [00:00<00:00, 1099.13it/s, Materializing param=encoder.layer.4.attention.self.query.weight]
Loading weights:  75%|#######4  | 77/103 [00:00<00:00, 1099.13it/s, Materializing param=encoder.layer.4.attention.self.query.weight]
Loading weights:  76%|#######5  | 78/103 [00:00<00:00, 1082.48it/s, Materializing param=encoder.layer.4.attention.self.value.bias]  
Loading weights:  76%|#######5  | 78/103 [00:00<00:00, 1067.62it/s, Materializing param=encoder.layer.4.attention.self.value.bias]
Loading weights:  77%|#######6  | 79/103 [00:00<00:00, 1081.31it/s, Materializing param=encoder.layer.4.attention.self.value.weight]
Loading weights:  77%|#######6  | 79/103 [00:00<00:00, 1081.31it/s, Materializing param=encoder.layer.4.attention.self.value.weight]
Loading weights:  78%|#######7  | 80/103 [00:00<00:00, 1080.22it/s, Materializing param=encoder.layer.4.intermediate.dense.bias]    
Loading weights:  78%|#######7  | 80/103 [00:00<00:00, 1080.22it/s, Materializing param=encoder.layer.4.intermediate.dense.bias]
Loading weights:  79%|#######8  | 81/103 [00:00<00:00, 1079.10it/s, Materializing param=encoder.layer.4.intermediate.dense.weight]
Loading weights:  79%|#######8  | 81/103 [00:00<00:00, 1079.10it/s, Materializing param=encoder.layer.4.intermediate.dense.weight]
Loading weights:  80%|#######9  | 82/103 [00:00<00:00, 1092.43it/s, Materializing param=encoder.layer.4.output.LayerNorm.bias]    
Loading weights:  80%|#######9  | 82/103 [00:00<00:00, 1092.43it/s, Materializing param=encoder.layer.4.output.LayerNorm.bias]
Loading weights:  81%|########  | 83/103 [00:00<00:00, 1091.23it/s, Materializing param=encoder.layer.4.output.LayerNorm.weight]
Loading weights:  81%|########  | 83/103 [00:00<00:00, 1091.23it/s, Materializing param=encoder.layer.4.output.LayerNorm.weight]
Loading weights:  82%|########1 | 84/103 [00:00<00:00, 1104.38it/s, Materializing param=encoder.layer.4.output.dense.bias]      
Loading weights:  82%|########1 | 84/103 [00:00<00:00, 1090.05it/s, Materializing param=encoder.layer.4.output.dense.bias]
Loading weights:  83%|########2 | 85/103 [00:00<00:00, 1095.74it/s, Materializing param=encoder.layer.4.output.dense.weight]
Loading weights:  83%|########2 | 85/103 [00:00<00:00, 1095.74it/s, Materializing param=encoder.layer.4.output.dense.weight]
Loading weights:  83%|########3 | 86/103 [00:00<00:00, 1108.64it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.bias]
Loading weights:  83%|########3 | 86/103 [00:00<00:00, 1108.64it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.bias]
Loading weights:  84%|########4 | 87/103 [00:00<00:00, 1105.80it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.weight]
Loading weights:  84%|########4 | 87/103 [00:00<00:00, 1105.80it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.weight]
Loading weights:  85%|########5 | 88/103 [00:00<00:00, 1118.51it/s, Materializing param=encoder.layer.5.attention.output.dense.bias]      
Loading weights:  85%|########5 | 88/103 [00:00<00:00, 1118.51it/s, Materializing param=encoder.layer.5.attention.output.dense.bias]
Loading weights:  86%|########6 | 89/103 [00:00<00:00, 1118.30it/s, Materializing param=encoder.layer.5.attention.output.dense.weight]
Loading weights:  86%|########6 | 89/103 [00:00<00:00, 1118.30it/s, Materializing param=encoder.layer.5.attention.output.dense.weight]
Loading weights:  87%|########7 | 90/103 [00:00<00:00, 1130.87it/s, Materializing param=encoder.layer.5.attention.self.key.bias]      
Loading weights:  87%|########7 | 90/103 [00:00<00:00, 1130.87it/s, Materializing param=encoder.layer.5.attention.self.key.bias]
Loading weights:  88%|########8 | 91/103 [00:00<00:00, 1129.22it/s, Materializing param=encoder.layer.5.attention.self.key.weight]
Loading weights:  88%|########8 | 91/103 [00:00<00:00, 1129.22it/s, Materializing param=encoder.layer.5.attention.self.key.weight]
Loading weights:  89%|########9 | 92/103 [00:00<00:00, 1141.63it/s, Materializing param=encoder.layer.5.attention.self.query.bias]
Loading weights:  89%|########9 | 92/103 [00:00<00:00, 1141.63it/s, Materializing param=encoder.layer.5.attention.self.query.bias]
Loading weights:  90%|######### | 93/103 [00:00<00:00, 1154.04it/s, Materializing param=encoder.layer.5.attention.self.query.weight]
Loading weights:  90%|######### | 93/103 [00:00<00:00, 1154.04it/s, Materializing param=encoder.layer.5.attention.self.query.weight]
Loading weights:  91%|#########1| 94/103 [00:00<00:00, 1152.19it/s, Materializing param=encoder.layer.5.attention.self.value.bias]  
Loading weights:  91%|#########1| 94/103 [00:00<00:00, 1152.19it/s, Materializing param=encoder.layer.5.attention.self.value.bias]
Loading weights:  92%|#########2| 95/103 [00:00<00:00, 1164.45it/s, Materializing param=encoder.layer.5.attention.self.value.weight]
Loading weights:  92%|#########2| 95/103 [00:00<00:00, 1164.45it/s, Materializing param=encoder.layer.5.attention.self.value.weight]
Loading weights:  93%|#########3| 96/103 [00:00<00:00, 1162.46it/s, Materializing param=encoder.layer.5.intermediate.dense.bias]    
Loading weights:  93%|#########3| 96/103 [00:00<00:00, 1162.46it/s, Materializing param=encoder.layer.5.intermediate.dense.bias]
Loading weights:  94%|#########4| 97/103 [00:00<00:00, 1174.57it/s, Materializing param=encoder.layer.5.intermediate.dense.weight]
Loading weights:  94%|#########4| 97/103 [00:00<00:00, 1174.57it/s, Materializing param=encoder.layer.5.intermediate.dense.weight]
Loading weights:  95%|#########5| 98/103 [00:00<00:00, 1186.68it/s, Materializing param=encoder.layer.5.output.LayerNorm.bias]    
Loading weights:  95%|#########5| 98/103 [00:00<00:00, 1172.47it/s, Materializing param=encoder.layer.5.output.LayerNorm.bias]
Loading weights:  96%|#########6| 99/103 [00:00<00:00, 1184.43it/s, Materializing param=encoder.layer.5.output.LayerNorm.weight]
Loading weights:  96%|#########6| 99/103 [00:00<00:00, 1156.76it/s, Materializing param=encoder.layer.5.output.LayerNorm.weight]
Loading weights:  97%|#########7| 100/103 [00:00<00:00, 1168.44it/s, Materializing param=encoder.layer.5.output.dense.bias]     
Loading weights:  97%|#########7| 100/103 [00:00<00:00, 1154.93it/s, Materializing param=encoder.layer.5.output.dense.bias]
Loading weights:  98%|#########8| 101/103 [00:00<00:00, 1166.48it/s, Materializing param=encoder.layer.5.output.dense.weight]
Loading weights:  98%|#########8| 101/103 [00:00<00:00, 1166.48it/s, Materializing param=encoder.layer.5.output.dense.weight]
Loading weights:  99%|#########9| 102/103 [00:00<00:00, 1178.03it/s, Materializing param=pooler.dense.bias]                  
Loading weights:  99%|#########9| 102/103 [00:00<00:00, 1164.58it/s, Materializing param=pooler.dense.bias]
Loading weights: 100%|##########| 103/103 [00:00<00:00, 1175.99it/s, Materializing param=pooler.dense.weight]
Loading weights: 100%|##########| 103/103 [00:00<00:00, 1175.99it/s, Materializing param=pooler.dense.weight]
Loading weights: 100%|##########| 103/103 [00:00<00:00, 1175.99it/s, Materializing param=pooler.dense.weight]
BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2
Key                     | Status     |  | 
------------------------+------------+--+-
embeddings.position_ids | UNEXPECTED |  | 

Notes:
- UNEXPECTED	:can be ignored when loading from different task/architecture; not ok if you expect identical arch.

Batches:   0%|          | 0/4 [00:00<?, ?it/s]
Batches:  25%|##5       | 1/4 [00:00<00:01,  2.66it/s]
Batches:  50%|#####     | 2/4 [00:00<00:00,  3.27it/s]
Batches:  75%|#######5  | 3/4 [00:00<00:00,  3.72it/s]
Batches: 100%|##########| 4/4 [00:00<00:00,  4.51it/s]
[OK] Generated 100 embeddings of dimension 384

[CLUSTER] Running HDBSCAN (min_cluster_size=3)...
[RESULT] Discovered 20 clusters
[INFO] Noise points (unclustered): 16
[METRIC] Silhouette score: 0.784

[REDUCE] Reducing to 2D with UMAP...
[OK] Reduced from 384D to 2D

[TOPIC] Running BERTopic modeling...
[RESULT] Discovered 4 topics

[TOPICS] Top discovered topics:
  Topic 0: 33 tickets - 0_app_for_mobile_on
  Topic 1: 14 tickets - 1_refund_months_get_received
  Topic 2: 14 tickets - 2_payment_card_was_402
  Topic 3: 12 tickets - 3_link_reset_password_expired

[VISUAL] Creating advanced visualizations...
  [OK] Saved: advanced_clustering.png
  [OK] Saved: temporal_advanced.png

======================================================================
[INSIGHTS] ADVANCED CLUSTERING DISCOVERIES
======================================================================

1. [CLUSTERS] Discovered Patterns:

   Cluster 0: 3 tickets
   Sample conversations:
   - Notification emails contain broken links....
   - Notification emails contain broken links....
   - Notification emails contain broken links....

   Cluster 1: 3 tickets
   Sample conversations:
   - Can you add export to Excel functionality?...
   - Can you add export to Excel functionality?...
   - Can you add export to Excel functionality?...

   Cluster 2: 5 tickets
   Sample conversations:
   - Export function generates corrupted PDF files....
   - Export function generates corrupted PDF files. This has been happening...
   - Export function generates corrupted PDF files....

   Cluster 3: 4 tickets
   Sample conversations:
   - File upload takes forever for large files....
   - Requesting batch upload feature for multiple files....
   - File upload takes forever for large files....

   Cluster 4: 3 tickets
   Sample conversations:
   - Two-factor authentication code never arrives....
   - Two-factor authentication code never arrives....
   - Two-factor authentication code never arrives....

   Cluster 5: 4 tickets
   Sample conversations:
   - Please add support for SSO with Google Workspace....
   - Please add support for SSO with Google Workspace....
   - Please add support for SSO with Google Workspace. Tried all troublesho...

   Cluster 6: 3 tickets
   Sample conversations:
   - Dashboard crashes when filtering by date range. Please escalate to sen...
   - Dashboard not loading - timeout error....
   - Dashboard crashes when filtering by date range. Multiple users affecte...

   Cluster 7: 3 tickets
   Sample conversations:
   - Search results showing wrong data after last update....
   - Search results showing wrong data after last update. This has been hap...
   - Search results showing wrong data after last update....

   Cluster 8: 3 tickets
   Sample conversations:
   - Missing data from yesterday's import....
   - Missing data from yesterday's import....
   - Missing data from yesterday's import. Please escalate to senior suppor...

   Cluster 9: 4 tickets
   Sample conversations:
   - Payment processing stuck at 'pending' for 24 hours. Urgent - this is b...
   - Payment processing stuck at 'pending' for 24 hours. Urgent - this is b...
   - Payment processing stuck at 'pending' for 24 hours....

   Cluster 10: 5 tickets
   Sample conversations:
   - Refund not received after 5 business days. Multiple users affected by ...
   - Refund not received after 5 business days....
   - Refund not received after 5 business days....

   Cluster 11: 5 tickets
   Sample conversations:
   - Can I get a refund for unused months?...
   - Can I get a refund for unused months?...
   - Can I get a refund for unused months?...

   Cluster 12: 7 tickets
   Sample conversations:
   - Payment failed with error code 402. Card was charged twice. Please esc...
   - Payment failed with error code 402. Card was charged twice....
   - Payment failed with error code 402. Card was charged twice. Multiple u...

   Cluster 13: 3 tickets
   Sample conversations:
   - Cannot add new payment method. System keeps rejecting my card. This ha...
   - Cannot add new payment method. System keeps rejecting my card....
   - Cannot add new payment method. System keeps rejecting my card....

   Cluster 14: 6 tickets
   Sample conversations:
   - Subscription renewal failed. Account suspended....
   - Subscription renewal failed. Account suspended....
   - Subscription renewal failed. Account suspended....

   Cluster 15: 3 tickets
   Sample conversations:
   - How do I cancel my subscription?...
   - How do I cancel my subscription?...
   - How do I cancel my subscription?...

   Cluster 16: 6 tickets
   Sample conversations:
   - Login button not responding on mobile app....
   - Login button not responding on mobile app....
   - Login button not responding on mobile app. Please escalate to senior s...

   Cluster 17: 6 tickets
   Sample conversations:
   - Password reset not working. Link expired....
   - Password reset not working. Link expired....
   - Password reset not working. Link expired. Multiple users affected by t...

   Cluster 18: 3 tickets
   Sample conversations:
   - Account locked after multiple login attempts. Tried all troubleshootin...
   - Account locked after multiple login attempts. This has been happening ...
   - Account locked after multiple login attempts....

   Cluster 19: 5 tickets
   Sample conversations:
   - Cannot log into my account. Getting 'invalid credentials' error. Tried...
   - Cannot log into my account. Getting 'invalid credentials' error....
   - Cannot log into my account. Getting 'invalid credentials' error....

2. [TIME] Temporal Patterns:
   Peak hour: 15:00 (14 tickets)
   Date range: 2026-02-08 to 2026-02-12
   Daily avg: 20.0 tickets

3. [STABILITY] Cluster Persistence:
   Cluster 0: Active for 1 days
   Cluster 1: Active for 3 days
   Cluster 2: Active for 3 days
   Cluster 3: Active for 3 days
   Cluster 4: Active for 4 days
   Cluster 5: Active for 4 days
   Cluster 6: Active for 2 days
   Cluster 7: Active for 4 days
   Cluster 8: Active for 4 days
   Cluster 9: Active for 2 days
   Cluster 10: Active for 1 days
   Cluster 11: Active for 3 days
   Cluster 12: Active for 3 days
   Cluster 13: Active for 1 days
   Cluster 14: Active for 4 days
   Cluster 15: Active for 2 days
   Cluster 16: Active for 4 days
   Cluster 17: Active for 3 days
   Cluster 18: Active for 1 days
   Cluster 19: Active for 4 days

4. [TOPICS] Semantic Topics Discovered:
   Topic 0: 33 tickets
   Keywords: app, for, mobile, on, support
   Topic 1: 14 tickets
   Keywords: refund, months, get, received, unused
   Topic 2: 14 tickets
   Keywords: payment, card, was, 402, twice
   Topic 3: 12 tickets
   Keywords: link, reset, password, expired, working

5. [NEXT] Recommended Actions:
   - Review Cluster 0 samples for common patterns
   - Schedule more support during peak hour (15:00)
   - Investigate 16 unclustered tickets
   - Build classifier to auto-tag new tickets

======================================================================

[OK] Saved enriched dataset: tickets_advanced_clustered.csv
[OK] Saved embeddings: embeddings.npy

======================================================================
[DONE] Phase 2 complete! Check PNG files for visualizations.
======================================================================
